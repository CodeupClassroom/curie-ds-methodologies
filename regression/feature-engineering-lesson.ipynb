{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "\"Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.\"\n",
    "Jason Brownlee, [Machine Learning Mastery](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n",
    "\n",
    "**Construct new features** using algorithms or domain knowledge\n",
    "\n",
    "**Select features** \n",
    "\n",
    "- **Use statistical tests** to determine each feature's usefulness in predicting the target variable. Rank the features and then select the K best features (Select K Best). (Filter Methods)\n",
    "\n",
    "- **Use the ML models** to determine each feature's usefulness in predicting the target variable. (Wrapper Methods)\n",
    "\n",
    "\n",
    "## Lesson Goals \n",
    "\n",
    "- We will use SelectKBest to select the top 2 features based on how correlated each feature is with the target variable. \n",
    "- We will use Recursive Feature Elimination and a linear regression algorithm to keep the top 2 features based on which features lead to the best performing linear regression model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import wrangle_grades\n",
    "import split_scale\n",
    "\n",
    "# acquire data and remove null values \n",
    "df = wrangle_grades.wrangle_grades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['student_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "train, test = split_scale.split_my_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "      <th>exam3</th>\n",
       "      <th>final_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    exam1  exam2  exam3  final_grade\n",
       "93     85     83     87           87\n",
       "35     62     70     79           70\n",
       "72     73     70     75           76\n",
       "87     62     70     79           70\n",
       "81     83     80     86           85"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the feature engineering methods, we want to use the scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data using standard scaler\n",
    "scaler, train, test = split_scale.standard_scaler(train, test)\n",
    "\n",
    "# to return to original values\n",
    "# scaler, train, test = scaling.my_inv_transform(scaler, train, test)\n",
    "\n",
    "X_train = train.drop(columns='final_grade')\n",
    "y_train = train[['final_grade']]\n",
    "X_test = test.drop(columns='final_grade')\n",
    "y_test = test[['final_grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select K Best \n",
    "\n",
    "- Filter method\n",
    "- Provide the algorithm with the test statistic to use to rank the variables. \n",
    "- Provide the desired number of features to end up with (K)\n",
    "\n",
    "### Steps to implement\n",
    "\n",
    "This is done in 2 steps behind the scenes when using the `SelectKBest` method with `f_regression`. \n",
    "\n",
    "1. The correlation between each regressor and the target is computed.    \n",
    "2. It is converted to an F score then to a p-value.    \n",
    "\n",
    "____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize the f_selector object, which defines the test for scoring the features and the number of features we want to keep, i.e. `k`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_selector = SelectKBest(f_regression, k = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit the object to our data. In doing this, our selector is scoring, ranking, and identifying the top `k` features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=2, score_func=<function f_regression at 0x104635840>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running correlation test between each x and y and returning the score, f-statistic\n",
    "\n",
    "f_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Transform our dataset to reduce to the `k` best features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 2)\n",
      "(71, 3)\n"
     ]
    }
   ],
   "source": [
    "# select the k best features\n",
    "X2 = f_selector.transform(X_train)\n",
    "\n",
    "print(X2.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest in one line\n",
    "\n",
    "We can simplify steps 1-3 in the following way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.53924057,  0.39096601],\n",
       "       [-1.16072052, -0.56211852]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = SelectKBest(f_regression, k = 2).fit_transform(X_train, y_train)\n",
    "print(X2.shape)\n",
    "\n",
    "X2[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `inverse_transform` function to return to the original variables. \n",
    "\n",
    "Get a list of the features selected using `get_support`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of features selected\n",
    "\n",
    "0. Use `.get_support` to get a list of booleans, a mask for the feature names or columns in X_train. \n",
    "1. Use `.loc` with our mask to subset to the features selected\n",
    "2. Use `.columns` to get the column names\n",
    "3. Convert the values to a list using `.tolist()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_support = f_selector.get_support()\n",
    "f_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exam1', 'exam3']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_feature = X_train.loc[:,f_support].columns.tolist()\n",
    "f_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of SelectKBest\n",
    "\n",
    "We used the `SelectKBest` method to select the top `k` features, and these features are scored and ranked using a statistical test, which we used the f-regression test in this case. \n",
    "\n",
    "\n",
    "## Recursive Feature Elimination\n",
    "\n",
    "- wrapper method\n",
    "- iterative & computationally expensive\n",
    "- more accurate and flexible than SelectKBest\n",
    "- ranks the variables (1 being most important, along with its support, True being relevant feature and False being irrelevant feature.)\n",
    "\n",
    "\n",
    "These are the steps we will take to implement RFE:  \n",
    "\n",
    "1. Initialize the linear regression object. `sklearn.linear_model.LinearRegression`  \n",
    "2. Initialize the RFE object. `sklearn.feature_selection.RFE`  \n",
    "3. Fit the RFE object to our data. `rfe.fit()`  \n",
    "4. Transform our X dataframe to include only those 2 features. `rfe.transform()`  \n",
    "\n",
    "Optional: Get list of features selected and/or ranking of all variables  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize the linear regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialize the RFE object, setting the hyperparameters to be our linear regression object created above (as the algorithm to test the features on) and the number of features to return to be 2.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(lm, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit the RFE object to our data. This means create multiple linear regression models, find the one that performs best, and identify the features that are used in that model. Those are the features we want.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False),\n",
       "  n_features_to_select=2, step=1, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Transform our X dataframe to include only those 2 features. `.transform()` *or do both of those steps together with `.fit_transform()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53924057,  0.39096601],\n",
       "       [-1.16072052, -0.56211852]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rfe = rfe.transform(X_train)\n",
    "X_rfe[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we move on to modeling, we would then use our new X dataframe as the one to move forward for actual modeling. As a sneak peak..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X_rfe, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "rfe = RFE(lm, 2)\n",
    "X_rfe = rfe.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For extra fun and sneak peak, let's just build the model with those features and make predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_grade</th>\n",
       "      <th>predicted_final_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.559281</td>\n",
       "      <td>0.505315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1.059549</td>\n",
       "      <td>-1.026019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-0.488197</td>\n",
       "      <td>-0.499429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-1.059549</td>\n",
       "      <td>-1.026019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.368830</td>\n",
       "      <td>0.364153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.488197</td>\n",
       "      <td>-0.499429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.130632</td>\n",
       "      <td>1.091416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-1.059549</td>\n",
       "      <td>-1.026019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.368830</td>\n",
       "      <td>0.364153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.368830</td>\n",
       "      <td>0.364153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     final_grade  predicted_final_grade\n",
       "93      0.559281               0.505315\n",
       "35     -1.059549              -1.026019\n",
       "72     -0.488197              -0.499429\n",
       "87     -1.059549              -1.026019\n",
       "81      0.368830               0.364153\n",
       "..           ...                    ...\n",
       "85     -0.488197              -0.499429\n",
       "19      1.130632               1.091416\n",
       "100    -1.059549              -1.026019\n",
       "94      0.368830               0.364153\n",
       "68      0.368830               0.364153\n",
       "\n",
       "[71 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['predicted_final_grade'] = lm.fit(X_rfe, y_train).predict(X_rfe)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of features selected and ranking of features\n",
    "\n",
    "For list of the features that remain, use `.support_` (like `.get_support()` with `SelectKBest`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exam1', 'exam3']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = rfe.support_\n",
    "rfe_features = X_train.loc[:,mask].columns.tolist()\n",
    "rfe_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ranking of the features using `rfe.ranking_`. \n",
    "\n",
    "- Will return a 1 for the features that were selected. \n",
    "- The features that were eliminated will be ranked accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exam1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exam2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exam3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Rank\n",
       "0   exam1     1\n",
       "1   exam2     2\n",
       "2   exam3     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ranks = rfe.ranking_\n",
    "var_names = X_train.columns.tolist()\n",
    "\n",
    "pd.DataFrame({'Feature': var_names, 'Rank': var_ranks})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of RFE\n",
    "\n",
    "Here we took LinearRegression model with 2 features and RFE gave feature ranking as above, but the selection of number ‘2’ was random. If you would like to learn how to find the optimum number of features, for which the accuracy is the highest, see the extended lesson in the appendix of ds.codeup.com.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- We used SelectKBest to select the top 2 features based on how correlated each feature is with the target variable. We ended up with exam1 and exam3.    \n",
    "- We use RFE and a linear regression algorithm to keep the top 2 features based on which features lead to the best performing linear regression model. This eliminated exam2 and also left us with exam1 and exam3, like SelectKBest. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
