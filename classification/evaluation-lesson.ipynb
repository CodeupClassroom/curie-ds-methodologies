{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model Evaluation\n",
    "\n",
    "- different domains have different needs\n",
    "\n",
    "    - iPhone face id -- high precision\n",
    "    - fraud detection -- high recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual prediction\n",
       "0     coffee  no coffee\n",
       "1  no coffee  no coffee\n",
       "2  no coffee     coffee\n",
       "3     coffee     coffee\n",
       "4     coffee     coffee\n",
       "5     coffee     coffee\n",
       "6  no coffee  no coffee\n",
       "7     coffee  no coffee"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'actual': ['coffee', 'no coffee', 'no coffee', 'coffee', 'coffee', 'coffee', 'no coffee', 'coffee'],\n",
    "    'prediction': ['no coffee', 'no coffee', 'coffee', 'coffee', 'coffee', 'coffee', 'no coffee', 'no coffee'],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>coffee</th>\n",
       "      <th>no coffee</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no coffee</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual      coffee  no coffee\n",
       "prediction                   \n",
       "coffee           3          1\n",
       "no coffee        2          2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.prediction, df.actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TP: predicted coffee + actual is coffee\n",
    "- FP: predicted coffee, but they didn't like coffee\n",
    "- FN: predicted no coffee, but really they liked coffee\n",
    "- TN: predicted no coffee, actual no coffee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- our choice of positive and negative is arbitrary\n",
    "- the labels / layout of the confusion matrix varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "- **accuracy**: (TP + TN) / (TP + TN + FP + FN)\n",
    "    - (3 + 2) / (3 + 1 + 2 +2) = 62.5%\n",
    "- **precision**: TP / (TP + FP)\n",
    "    - 3 / (3 + 1) = 75%\n",
    "    - FP is more costly than FN\n",
    "- **recall**: TP / (TP + FN)\n",
    "    - 3 / (3 + 2) = 60%\n",
    "    - FN is more costly than FP\n",
    "    \n",
    "Imagine you're bringing coffee to meeting, which metric would we choose? It depends\n",
    "\n",
    "Outcomes:\n",
    "\n",
    "- FP: Buy a coffee for someone who won't drink it\n",
    "- FN: Don't buy a coffee for someone who wanted one\n",
    "- TP: Buy a coffee for someone who will drink it\n",
    "- TN: Don't buy a coffee for someone who wouldn't drink it anyway\n",
    "\n",
    "Scenarios\n",
    "\n",
    "- lola: really good coffee, but super expensive\n",
    "    - cost of a FP is higher than FN\n",
    "    - precision is better here because buying a cup of coffee for someone who won't drink it is expensive\n",
    "    - We want to be sure about our positive predictions\n",
    "- taco cabana: bad coffee, but cheap\n",
    "    - cost of a FN is higher than FP\n",
    "    - recall because the coffee is cheap, its not bad to buy a cheap coffee for someone who won't drink it; worse to not get someone coffee who wanted it\n",
    "- meeting with super important client\n",
    "    - cost of FN is higher, because they might be offended if we dont' get them coffee\n",
    "    - cost of FN == not signing a contract\n",
    "    - recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we just don't buy coffee or buy coffee for everyone? Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coffee       5\n",
       "no coffee    3\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['baseline'] = 'coffee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual prediction baseline\n",
       "0     coffee  no coffee   coffee\n",
       "1  no coffee  no coffee   coffee\n",
       "2  no coffee     coffee   coffee\n",
       "3     coffee     coffee   coffee\n",
       "4     coffee     coffee   coffee\n",
       "5     coffee     coffee   coffee\n",
       "6  no coffee  no coffee   coffee\n",
       "7     coffee  no coffee   coffee"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model accuracy\n",
    "(df.actual == df.prediction).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "(df.actual == df.baseline).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      actual prediction baseline\n",
      "2  no coffee     coffee   coffee\n",
      "3     coffee     coffee   coffee\n",
      "4     coffee     coffee   coffee\n",
      "5     coffee     coffee   coffee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision -- how good are our positive predictions\n",
    "# precision -- model performance | pred +\n",
    "subset = df[df.prediction == 'coffee']\n",
    "print(subset)\n",
    "(subset.prediction == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actual prediction baseline\n",
      "0  coffee  no coffee   coffee\n",
      "3  coffee     coffee   coffee\n",
      "4  coffee     coffee   coffee\n",
      "5  coffee     coffee   coffee\n",
      "7  coffee  no coffee   coffee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall -- how often do we get the actual positive cases\n",
    "# recall -- model performance | actual +\n",
    "subset = df[df.actual == 'coffee']\n",
    "print(subset)\n",
    "(subset.prediction == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will the precision and recall of our baseline model that always predicts + be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      actual prediction baseline\n",
      "0     coffee  no coffee   coffee\n",
      "1  no coffee  no coffee   coffee\n",
      "2  no coffee     coffee   coffee\n",
      "3     coffee     coffee   coffee\n",
      "4     coffee     coffee   coffee\n",
      "5     coffee     coffee   coffee\n",
      "6  no coffee  no coffee   coffee\n",
      "7     coffee  no coffee   coffee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "subset = df[df.baseline == 'coffee']\n",
    "print(subset)\n",
    "(subset.baseline == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actual prediction baseline\n",
      "0  coffee  no coffee   coffee\n",
      "3  coffee     coffee   coffee\n",
      "4  coffee     coffee   coffee\n",
      "5  coffee     coffee   coffee\n",
      "7  coffee  no coffee   coffee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall\n",
    "subset = df[df.actual == 'coffee']\n",
    "print(subset)\n",
    "(subset.baseline == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Example\n",
    "\n",
    "Predict whether an email is spam or not.\n",
    "\n",
    "- positive case: spam\n",
    "- negative case: not spam\n",
    "\n",
    "Outcomes:\n",
    "\n",
    "- TP: predict that a message is spam, and it really is\n",
    "- FP: predict that a message is spam, but its really not\n",
    "- FN: predict that a message is not spam, but it really is\n",
    "- TN: predict that a message is not spam, and it really is not spam\n",
    "\n",
    "Which has a higher cost, a false negative or false positive?\n",
    "\n",
    "FP -- its **_bad_** to put bill in accounting's email in your spam folder\n",
    "\n",
    "Precision: because we want to be certain a message really is spam when we send it to the spam folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phishing Example\n",
    "\n",
    "Predict whether an email is a phishing attempt. When we predict positive, show an additional banner\n",
    "\n",
    "- positive case: phishing attempt\n",
    "- negative case: legit email\n",
    "\n",
    "Outcomes:\n",
    "\n",
    "- FP: Show a warning about phishing on a legit email\n",
    "- TP: Show a warning about phishing on a phishing email\n",
    "- FN: Don't show a warning on a phishing email\n",
    "- TN: Don't show a warning on a legit email\n",
    "\n",
    "Which has the highest cost? FN: not showing a warning on a phishing email\n",
    "\n",
    "The cost of showing a banner on a legit email is less than not showing the warning on a phishing.\n",
    "\n",
    "Optimize for recall in our phishing detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does \"positive\" mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model accuracy: 62.50%\n",
      "baseline accuracy: 62.50%\n",
      "\n",
      "   model recall: 60.00%\n",
      "baseline recall: 100.00%\n",
      "\n",
      "model precision: 75.00%\n",
      "baseline precision: 62.50%\n"
     ]
    }
   ],
   "source": [
    "positive = 'coffee'\n",
    "\n",
    "# accuracy -- overall hit rate\n",
    "model_accuracy = (df.prediction == df.actual).mean()\n",
    "baseline_accuracy = (df.baseline == df.actual).mean()\n",
    "\n",
    "# precision -- how good are our positive predictions?\n",
    "# precision -- model performance | predicted positive\n",
    "subset = df[df.prediction == positive]\n",
    "model_precision = (subset.prediction == subset.actual).mean()\n",
    "subset = df[df.baseline == positive]\n",
    "baseline_precision = (subset.baseline == subset.actual).mean()\n",
    "\n",
    "# recall -- how good are we at detecting actual positives?\n",
    "# recall -- model performance | actual positive\n",
    "subset = df[df.actual == positive]\n",
    "model_recall = (subset.prediction == subset.actual).mean()\n",
    "baseline_recall = (subset.baseline == subset.actual).mean()\n",
    "\n",
    "\n",
    "print(f'   model accuracy: {model_accuracy:.2%}')\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')\n",
    "print()\n",
    "print(f'   model recall: {model_recall:.2%}')\n",
    "print(f'baseline recall: {baseline_recall:.2%}')\n",
    "print()\n",
    "print(f'model precision: {model_precision:.2%}')\n",
    "print(f'baseline precision: {baseline_precision:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "In short:\n",
    "\n",
    "- optimize for **precision** when you want to be sure about your positive predictions\n",
    "- optimize for **recall** when you don't want to miss positive cases "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
